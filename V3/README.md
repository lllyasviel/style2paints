# Welcome to PaintsTransfer-Euclid (Style2Paints V3) !

**Can you colorize line arts?**

**If yes, you will do it faster if you can read this page.**

**If no, you will be able to do it if you can read this page.**

*(PaintsTransfer-Euclid is the new name of style2paintsV3.)*

The AI can paint on a sketch, obeying your instructions.

The AI can paint on a sketch according to a given specific color style.

The AI can create its own color style to paint on a sketch.

The AI can transfer illustrations' style.

We focus on interactivity, possibility and creativity.

![web_preview](https://raw.githubusercontent.com/lrisviel/markdown/master/github/0.jpg)

## An Overview

![glance](https://github.com/lllyasviel/style2paints/raw/master/temps/glance.jpg)

# Colorize Line Arts In 3 minutes

[3 minutes fast colorization in PaintsTransfer 002](https://youtu.be/FBP9JuthyOQ) (YouTube)

[3 minutes fast colorization in PaintsTransfer 002](https://youtu.be/G8aKt5PO77M) (YouTube)

[3 minutes fast colorization in PaintsTransfer 003](https://youtu.be/Ul3kBlmM3JA) (YouTube)

[3 minutes fast colorization in PaintsTransfer 004](https://youtu.be/k4nnK-LgW7E) (YouTube)

[3 minutes fast colorization in PaintsTransfer 001 - 003](https://www.bilibili.com/video/av22709469/) (BiliBili搬运) (NOT official)

## SEX OR VIOLENCE WARNING

Contents below may include:

    1. Arts with female body.
    2. Arts with nude skin.
    3. Asia style arts of girls with short skirts, low bosom elements, lolita or others.
    4. All virtual characters are more than 18 years old.

**If you feel uncomfortable about these elements, you can stop reading here.**

**You should stop reading if you are under 14 years old.**

**You have been warned.**

# New Feature: The Geometric Color Anchor

**This github page contains many gif and png images, and it is a better choice to wait your browser before reading it.**

To introduce this feature, let's begin with a kimono sketch of Shiki. The sketch is from google image.

![gif0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/gif0.gif)

The new tool, color anchor, enable you to control the color of your painting with great stability. In most cases, you can use this tool to control the global color of the painting. **In most cases, casting the color anchors should be your first step.**

After this step, you should get a color draft like this:

![display1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/display1.jpg)

Then, after you finishing your color draft, you should shift to your **Accurate Point** tool. 

![display2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/display2.jpg?t=233)

Then, you add hint colors and get the final result, like this:

![display3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/display3.jpg)

Here is a gif version of the process:

![gif1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/gif1.gif)

## All you need to know:

We provide some best-practice for you:

**If you are an artist, we highly recommend you to read these key points!!**

    1. When color anchors are linked, it means that colors on the line may be 
       fused in the final result.
    
    2. Each color anchor has a range circle, it means areas in the cicles may 
       be infuenced. 
    
    3. Color Anchors does (!!!!!!!!!)NOT(!!!!!!!!!) influence the final color, 
       it only influence the color style of the result.
       Thus, DO NOT ONLY use Color Anchors.
       
    4. Accurate Points will only influence detailed, small, minor color area.
       Thus, DO NOT ONLY use Accurate Points.
       
    5. In most cases, you can put some Accurate Points around a Color Anchor,
       with same color. But for advanced usage, you can put Accurate Points
       around anchors with different colors.
       
    6. You should NOT put Color Anchors with all same color. For example, 
       instead of put 8 blue Color Anchors, You should put 3 blue ones, 2
       black ones, 2 white ones and 1 green one. Otherwise the result color
       will be ugly and unbalanced.
       
![right](https://raw.githubusercontent.com/lrisviel/markdown/master/github/right.jpg)
    
In the same way, you can get many Shiki with different color, such as:

![s1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sh1.jpg)

![s2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sh2.jpg)

![s3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sh3.jpg)

After reading these, you may ask: 

*"Oh, you are just good at color selection! But I am blind to these color and I have never learnt to painting! How can I select right color?"*

Ok, here we present a best-practice color list for you:

![display4](https://raw.githubusercontent.com/lrisviel/markdown/master/github/display4.jpg?t=233)

# You can still use reference images in V3.

You can still upload your reference, but keep in mind that you need to **drag** the "stylizing rate" slider.

Here is an example with reference image:

![omg](https://raw.githubusercontent.com/lrisviel/markdown/master/github/omg.jpg?t=233)

*We do NOT recommend you to paint in this way, because it is hard to find suitable reference images.*

Anyway, I selected some good reference images for you:

https://github.com/lllyasviel/lllyasviel.github.io/raw/master/default_references.zip

# New Feature: The Controlable Shading

Let's begin with one of the promotion sketch of our friend paintschainer *(paintschainer.preferred.tech)*. 

You can find this sketch here:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/dis5.jpg" height = "300" />

Here is a overview of this feature:

![shading](https://raw.githubusercontent.com/lrisviel/markdown/master/github/shading.jpg)

Here we explain what happen. First of all, you just make a normal paintstransfer painting, like this:

![screen0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/screen0.jpg)

Then we select colors for shadow.

![colorshadow](https://raw.githubusercontent.com/lrisviel/markdown/master/github/colorshadow.jpg)

Then you use these four step to get the shadow.

![shadowhints](https://raw.githubusercontent.com/lrisviel/markdown/master/github/shadowhints.jpg)

![sa0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sa0.jpg)

We can also change the dress into black, and use similar method to reach a highlight shading:

![shadow2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/shadow2.jpg)

![ssa](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ssa.jpg)

Some other similar examples:

![se0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/se0.jpg)

![se1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/se1.jpg)

# New Feature: The New Skin Engine

Let us begin with a sketch from google, and this sketch has relative large skin area:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/sketch.original.jpg" height = "300" />

And here is the result from **PaintsChainer** :

![pc](https://raw.githubusercontent.com/lrisviel/markdown/master/github/pc.jpg)

As we can see, the skin rendering is very hard for AI. But we have a new Skin Engine, and here is our result.

![sk0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sk0.jpg)

And some other similar results:

![sk1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sk1.jpg)

![sk3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sk3.jpg)

[Another NSFW result](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sk2.jpg)

## Our baseline sample of skin rendering

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/sbl2.jpg" height = "360" />

![sbl1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sbl1.jpg)

# Some Other Results of Male

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/001.jpg?t=7879)

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/002.jpg?t=7879)

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/003.jpg?t=7879)

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/004.jpg?t=7879)

# Some Other Results of Special Style

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/005.jpg?t=7879)

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/006.jpg?t=7879)

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/007.jpg?t=7879)

# Or landscapes

![001](https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/008.jpg?t=7879)

## How can I get these skin rendering on my own sketch?

Because our software is designed for professional use, you need to know what is skin color first. It is easy:

![color3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/color3.jpg?t=987)

And then, you need to try some of these to get your favorite one. Do not be lazy.

Here is an Ayase for you to practice:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/huili.jpg" height = "360" />

![skinright](https://raw.githubusercontent.com/lrisviel/markdown/master/github/skinright.jpg)

# New Feature: The Outline Emphasizer

Sometimes you may want to emphasize the lines so as to achieve a natural painting. Then we have developed the standalone **Outline Emphasizer**:

![ous](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ous.jpg)

Let begin with a sample of sakura:

![sakura](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sakura.jpg)

Then, we enable the **Outline Emphasizer** and we can get this result:

![sakura2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sakura2.jpg)

Here is a comparison:

![com01](https://raw.githubusercontent.com/lrisviel/markdown/master/github/com01.jpg)

Another example with **Outline Emphasizer**:

![ane0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ane0.jpg)

Without **Outline Emphasizer**:

![ane1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ane1.jpg)

Here is a comparison:

![cp2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/cp2.jpg)

# Let us have a step by step practice!

Here is a Minami for you:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/xn.jpg" height = "300" />

First of all, you just upload this sketch to the APP and click one of the right arrows to get the automatic result, like this:

![as1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/as1.jpg?t=1)

Then, you may change the overall color. In my case, I use 7 color anchors, like this:

![as2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/as2.jpg?t=1)

Then, you see that color anchors will **NOT** directly influence the final color. We only use color anchor to suggest the neural network to **create a color atomosphere**. In the image above, I put two pink color anchors on the wings and one color anchor on the shose, but these objects are still white in final results. Here is an example:

![ane](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ane.jpg?t=y)

Then, we come to the important step: We need to make sure of these color. We need to tell the neural network what we really need.

First of all, we make sure of the pink wings:

![ds1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds1.jpg?t=1)

Is it easy? We only add some accurate pink points, and this will tell the AI that you need a pink color block. Then we continue with the face and hair:

![ds2](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds2.jpg?t=1)

Still, it is very easy. We add gray points on hair, and white points on backgrounds. Then, we continue with the skirt:

![ds3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds3.jpg?t=1)

OK. Still very easy, just put white color on the skirt. This is important because if you do not do that, the AI will not know you need a white skirt. You need to use these points to tell the AI that "you are right", otherwise the AI will be confused and it will hesitate to use these colors.

![ds5](https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds5.jpg?t=1)

OK. The shose and leg color are checked. Then we add color to the skin:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds6.jpg" height = "500" />

And we make some final decoration and get this:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/ds7.jpg" height = "500" />

As you can see, this canvas seems very complex, but it is very easy to create if you can follow these steps.

And here is the result:

![as3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/as3.jpg?t=1)

Another similar result in the same way:

![as4](https://raw.githubusercontent.com/lrisviel/markdown/master/github/as4.jpg?t=1)

# Repaint Mode (Re-Colorization Mode)

**NOTICE!! This feature is NOT stable currently !!**

If you upload a finished painting and shift to the re-colorization mode, the software will give you a sketch extracted from the painting and it will paint on the new sketch again, obying your hints.

Here is an example:

![violet](https://raw.githubusercontent.com/lrisviel/markdown/master/github/violet.jpg)

My 《Deep Violet Fantasy》, a result of **Re-Colorization Mode** in PaintsTransferV3. Original Image is from [Here](https://raw.githubusercontent.com/lrisviel/markdown/master/github/or1.jpg). 

Here is how I create it:

![st0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/st0.jpg)

Some other examples:

Origins:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/ors.jpg?t=55" height = "180" />

Results:

![st0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/st1.jpg)

![st0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/st3.jpg)

## A trick - the rerendering mode

Sometimes your sketch may not combines of lines, or the sketch itself is a black-and-white illustration. 

Then you may need this mode. For example, this sketch:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/baws.jpg" height = "250" />

And the results:

![blac](https://raw.githubusercontent.com/lrisviel/markdown/master/github/bawc.jpg)

## A trick - get the pure sketch from sketch

Sometimes your sketch may not combines of lines, and then you can use **Re-Colorization Mode** option to get the pure sketch.

![spt](https://raw.githubusercontent.com/lrisviel/markdown/master/github/sksk.jpg)

# Create special texture

**NOTICE!! This feature is NOT stable currently !!**

You can create some special texture like:

![spt](https://raw.githubusercontent.com/lrisviel/markdown/master/github/spt.jpg)

# Extreme Hint Density Holder

Our new engine can hold as much as possible hints, without causing disordering or blurring. 

Here is some example when there are LOTS of user hints:

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e0.jpg)

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e1.jpg)

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e2.jpg)

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e3.jpg)

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e4.jpg)

![hss](https://raw.githubusercontent.com/lrisviel/markdown/master/github/e7.jpg)

## Whatever you get, never give up your painting!

In many cases, you may get a not very good result, with disordered color or ugly compositions.

But keep in mind that you should not give up this painting! 

In our study, we find that more than 70% bad paintings have potential to become fine arts, and they just need your extra 5 minutes to put some hints!!

For example, this painting looks not good at all, when we finish the color anchor:

![nbefore](https://raw.githubusercontent.com/lrisviel/markdown/master/github/nbefore.jpg)

![nbefore](https://raw.githubusercontent.com/lrisviel/markdown/master/github/n2before.jpg)

But if you can spend your extra minutes, making some extra efforts, things may be a bit better:

![nafter](https://raw.githubusercontent.com/lrisviel/markdown/master/github/nafter.jpg)

![nafter](https://raw.githubusercontent.com/lrisviel/markdown/master/github/n2after.jpg)

One of the main advantage of PaintsTransfer is: no matter how much hint points you put, the results will never be blured because of this.

**Then you may ask: OMG! Then I need to add sooooooo many points? It is so difficult and not practical at all!!**

**In fact, though there are many points, most of these points are just of same color. You only need to select one color and then click, click, click, click, click, click....　It is very easy! If you have actually tried, you will find that it do not require any art knowledge.**

# The Palette Prediction for Lazy Users

**NOTICE!! This feature is NOT stable currently !!**

**Lazy** users are those who do not want to input any instructions. For those users, we updated our core models so as to make the results reasonable when there are no user hints.

**All below results are achieved without human hints, or with minor detailed hints:**

![w0](https://raw.githubusercontent.com/lrisviel/markdown/master/github/w0.jpg)

![w1](https://raw.githubusercontent.com/lrisviel/markdown/master/github/w1.jpg)

![w3](https://raw.githubusercontent.com/lrisviel/markdown/master/github/w3.jpg)

![w4](https://raw.githubusercontent.com/lrisviel/markdown/master/github/w4.jpg)

![w5](https://raw.githubusercontent.com/lrisviel/markdown/master/github/w5.jpg)

# What our AI like and what our AI dislike

Our AI has its own hobbies. You can get good results if the AI *like* your sketches. But if our AI *dislike* your sketch, you would better go to paintschainer (http://paintschainer.preferred.tech).

Here is a list:

![dont](https://raw.githubusercontent.com/lrisviel/markdown/master/github/dont.jpg)

# Manga Colorization

Currently, our model is designed to colorize sketch, not manga.

In the near future, we will **NOT** work on **Manga Colorization** because our friend PaintsChainer is working on it, and we do not want to see the research community of Manga Colorization be under great pressure.

If you are interested in Manga Colorization, just do your research! 

# Next Step

Currently, the baseline of sketch colorization is very high (PaintsChainerV1/V2/V3+PaintsTransferV2/V3), but still, there remains great improvement space. 

For example, if someone can train a model to colorize this:

<img src="https://raw.githubusercontent.com/lrisviel/markdown/master/github/bs.jpg" height = "512" />

Then we will appreciate it very much, because it remains a BIG problem how we can improve sketch itself. BTW, our result is here:

![bad](https://raw.githubusercontent.com/lrisviel/markdown/master/github/bad.jpg)

Or we want to see a method to do image to image translation like this:

![impos](https://raw.githubusercontent.com/lrisviel/markdown/master/github/impos.jpg)

# Video Tutorials

[How to get high quality paintings from line sketches in PaintsTransfer (for non-artist)](https://youtu.be/u8bvHDDstlY)

# Latest News

2018.4.28 - PaintsTransfer-Euclid released.

2018.4.16 - We changed our time schedule:

    1. PaintsTransfer V3 will have an online demo, and V2 demo will not be avaliable online anymore.
    2. PaintsTransfer V3 can do all what V2 can do (in theory).
    3. PaintsTransfer V3 will be renamed into PaintsTransfer-Euclid V1.0.
    4. PaintsTransfer-Euclid will be released at 2018.04.28 23:59 CST.

2018.4.13 - A good news: PaintsTransfer V3 is decided to be released at 2018.04.28-2018.04.30. Have a magical day!

2018.4.13 - A good news: We finally get the server. PaintsTransfer V2 will be avaliable again before 2018.04.13.

2018.4.6 - A bad news: We have developed paintstransfer V3, but it is defeated by V2. Theoretically, the deeper V3 should be better than V2 but our user studies show that V2 is still the best painter. 

*The consequence is:*

    50% possibility: We will combine some good part of unfinished V3 into V2 and release V2.5. 
                     And V3 will not be released.
    50% possibility: We will improve V3 and release V3.


2018.2.12 - PaintsTransfer 3.0 will be released in 2018.04.25-2018.05.15. We will use a totally non-residual very deep model.

2018.2.3 - We added the *super accurate pencil*, and the original pencil tool is replaced by *brush*. The problem of over colorization in non-reference mode is fixed when you use the *super accurate pencil*, and the color spreading of *super accurate pencil* is limited to a relative small degree.

2018.01.15 - PaintsTransfer V2.1 released.

2017.12.29 - PaintsTransfer V2.0 released.

2017.10.23 - PaintsTransfer released.

# Launch Server

*you need a python 3.5/3.6 GPU environment with cuda.*

    pip install tensorflow_gpu
    pip install keras
    pip install bottle
    pip install gevent
    pip install h5py
    pip install paste
    pip install opencv-python
    pip install scikit-image
    git clone https://github.com/lllyasviel/style2paints.git
    
Then you need to download all models from our Google Drive and put these into 'server' folder.
    
    cd style2paints/server
    python server.py


# Models

Currently, we reserve all rights about all these models. 

We use Google Drive to upload models:

    https://drive.google.com/open?id=1fWi4wmNj-xr-nCzuWMsN2rcm0249_Aem
    
Current model list of the 6 neural networks:

    baby.net
    head.net
    neck.net
    tail.net
    reader.net
    girder.net

# Training Datasets

**We do not use additional training data.**

**Danbooru2017 is highly recommended.**

1. The recommended training dataset of illustrations is the 400k images from [nico-opendata](https://nico-opendata.jp/en/seigadata/index.html) and [Danbooru2017](http://www.gwern.net/Danbooru2017).

2. The recommended training sketches is from [sketchKeras](https://github.com/lllyasviel/sketchKeras).

# 中文社区

欢迎加入以下500人qq群，但是不保证一直有空位，如果你一次加群失败，可以多次尝试。

    纸片协会总舵-圣辇船（已经满了不要加）：184467946

## Acknowledgements

Thanks a lot to TaiZan. This project could not be achieved without his great help.

    @Article{ACMTOGTSC2018,
      author  = {LvMin Zhang, Chengze Li, Tien-Tsin Wong, Yi Ji and ChunPing Liu},
      title   = {Two-stage Sketch Colorization},
      journal = {ACM Transactions on Graphics},
      year    = {2018},
      volume  = {37},
      number  = {6},
      month   = nov,
      doi     = {https://doi.org/10.1145/3272127.3275090},
    }
